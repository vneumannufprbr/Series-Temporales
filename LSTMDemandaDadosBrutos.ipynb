{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vneumannufprbr/Series-Temporales/blob/main/LSTMDemandaDadosBrutos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xmGxFa6jbbB"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova seção"
      ],
      "metadata": {
        "id": "PLfxODpHUn-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY0PDqUvj9o7"
      },
      "outputs": [],
      "source": [
        "# Importações\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# incluido por VN\n",
        "# correlograma e sazonalidade para determinar tamanho da janela (window size)\n",
        "import statsmodels.api as sm\n",
        "# Livraria para preprocessamento\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from scipy.stats import iqr\n",
        "# Livaria para autoajuste de parâmetros\n",
        "!pip install keras-tuner\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "# Livaria pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.core import window\n",
        "from pandas.core import indexes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfu_lWRsF0MJ"
      },
      "outputs": [],
      "source": [
        "# Carga da base\n",
        "#df = pd.read_csv(\"/content/drive/Othercomputers/Meu computador/Google Drive/Especialização IA UFPR/AAA-Curso IA UFPR/Arquitetura de Dados/Artigos de AI aplicada a Sistemas de Energia/ENCONTRO 02/archive/energy_dataset.csv\",  low_memory=False) # dtype=dtype_dict,\n",
        "!git clone https://github.com/vneumannufprbr/Series-Temporales.git\n",
        "df = pd.read_csv('Series-Temporales/energy_dataset.csv',  low_memory=False) # dtype=dtype_dict,\n",
        "dtype_dict = {\n",
        "    'time': str,\n",
        "    'generation biomass': float,\n",
        "    'generation fossil brown coal/lignite': float,\n",
        "    'generation fossil gas': float,\n",
        "    'generation fossil hard coal': float,\n",
        "    'generation fossil oil': float,\n",
        "    'generation hydro pumped storage consumption': float,\n",
        "    'generation hydro run-of-river and poundage': float,\n",
        "    'generation hydro water reservoir': float,\n",
        "    'generation nuclear': float,\n",
        "    'generation solar': float,\n",
        "    'generation waste': float,\n",
        "    'generation wind onshore': float,\n",
        "    'forecast solar day ahead': float,\n",
        "    'forecast wind onshore day ahead': float,\n",
        "    'total load forecast': float,\n",
        "    'total load actual': float,\n",
        "    'price day ahead': float,\n",
        "     # ... especificar outros tipos de dados das colunas aqui\n",
        "    'price actual': float\n",
        "}\n",
        "print(df.dtypes)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck6ZmL-eTUYN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wibjlUq_lZML"
      },
      "outputs": [],
      "source": [
        "df.index = pd.to_datetime(df['time'], format='mixed', utc=True)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6WMNGrNrLSo"
      },
      "outputs": [],
      "source": [
        "ger_real = df['total load actual']\n",
        "ger_solar_predito_origem = df['total load forecast']\n",
        "#ger_real[-240:].plot(label=\"Valores reais\")\n",
        "#plt.figure(figsize=(10, 6))\n",
        "plt.plot(ger_real[-24*30:], label='Valores reais')\n",
        "plt.plot(ger_solar_predito_origem[-24*30:], label='Valores preditos originais')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylabel('Potência (MW)')\n",
        "plt.xlabel('Data (Ano-Mês-Dia)')\n",
        "plt.xticks(rotation='vertical');"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-processamento\n",
        "# incluido por VN\n",
        "\n",
        "# Use o transformador para aplicar a função aos seus dados\n",
        "# Defina uma função personalizada para calcular o IQR\n",
        "#series=ger_real.values.reshape(-1, 1)\n",
        "#def interquartile(series):\n",
        "#  return iqr(series)\n",
        "\n",
        "# Crie um transformador de função usando a função personalizada\n",
        "#transformer = FunctionTransformer(interquartile, validate=False)\n",
        "\n",
        "# Use o transformador para aplicar a função aos seus dados\n",
        "#series = transformer.transform(series)\n",
        "# Os outliers foram eliminados\n",
        "\n",
        "#dados_transformados = transformer.transform(data)\n",
        "# Os outliers foram eliminados\n",
        "\n",
        "#dados_transformados.head()\n",
        "#plt.plot(data)\n",
        "#plt.show()\n",
        "#values1 = df['generation_solar']\n",
        "#series = values1.values.reshape(-1, 1)\n",
        "\n",
        "# Calcular o IQR usando a função quantile() do pandas\n",
        "Q1 = ger_real.quantile(0.25)\n",
        "Q3 = ger_real.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Definir limites superior e inferior\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filtrar outliers\n",
        "ger_real_filt = ger_real[(ger_real >= lower_bound) & (ger_real <= upper_bound)]\n",
        "\n",
        "# Verificar a quantidade de outliers removidos\n",
        "outliers_removed = len(ger_real) - len(ger_real_filt)\n",
        "print(\"Outliers removidos:\", outliers_removed)\n",
        "ger_real=ger_real_filt\n",
        "series = ger_real.values.reshape(-1, 1)\n",
        "series = series.astype('float64')\n",
        "\n",
        "# Normalizar os dados da série\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "series = scaler.fit_transform(series)\n",
        "ger_real=pd.Series(series.flatten())"
      ],
      "metadata": {
        "id": "giz9Cua8Tjj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlograma e sazonalidade para determinar tamanho da janela (window size)\n",
        "# Calcular o correlograma\n",
        "acf = sm.tsa.acf(ger_real)\n",
        "\n",
        "# Plotar o correlograma\n",
        "lags = range(1, len(acf)+1)\n",
        "#plt.figure(figsize=(10, 6))\n",
        "plt.bar(lags, acf)\n",
        "plt.xlabel('Lag (atraso)')\n",
        "plt.ylabel('Autocorrelação')\n",
        "#plt.title('Correlograma')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7YgrrCigU0xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a série temporal para identificar a sazonalide\n",
        "# Definir a série temporal\n",
        "dates = pd.date_range(start='2018-01-01', periods=365, freq='d')\n",
        "series2 = pd.Series(ger_real.values[-365:], index=dates)\n",
        "\n",
        "# Converter o índice para um DatetimeIndex\n",
        "series2.index = pd.DatetimeIndex(series2.index)\n",
        "\n",
        "# Decompor a série temporal\n",
        "decomposition = sm.tsa.seasonal_decompose(series2, model='additive')\n",
        "\n",
        "# Obter as componentes\n",
        "trend = decomposition.trend\n",
        "seasonal = decomposition.seasonal\n",
        "residual = decomposition.resid\n",
        "\n",
        "# Plotar as componentes\n",
        "#plt.figure(figsize=(10, 8))\n",
        "plt.subplot(411)\n",
        "plt.grid(True)\n",
        "plt.plot(series2, label='Dados originais normalizados do último ano')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.grid(True)\n",
        "plt.plot(trend, label='Tendência')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.grid(True)\n",
        "plt.plot(seasonal, label='Sazonalidade')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.grid(True)\n",
        "plt.plot(residual, label='Resíduo')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_FwWGi67U9mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbof54TusLdJ"
      },
      "outputs": [],
      "source": [
        "# Tamanho da janela que o correlograma e sazonalidade sugerem: 24h\n",
        "window_size = 24\n",
        "from pandas.core import window\n",
        "def df_to_X_y(df, window_size):\n",
        "  df_as_np = df.to_numpy()\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(len(df_as_np)-window_size):\n",
        "    row = [[a] for a in df_as_np[i:i+window_size]]\n",
        "    X.append(row)\n",
        "    label = df_as_np[i+window_size]\n",
        "    y.append(label)\n",
        "  return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V8aOXP2utHI"
      },
      "outputs": [],
      "source": [
        "X, y = df_to_X_y(ger_real, window_size)\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUC73B5Awsw3"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = X[:int(0.8*len(ger_real))], y[:int(0.8*len(ger_real))]\n",
        "X_val, y_val  = X[int(0.8*len(ger_real)):int(0.9*len(ger_real))], y[int(0.8*len(ger_real)):int(0.9*len(ger_real))]\n",
        "X_test, y_test = X[int(0.9*len(ger_real)):], y[int(0.9*len(ger_real)):]\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Autoajuste de hiperparâmetros\n",
        "# Se usa a função keras_tuner do pacote Keras-Tuner para fazer a busca\n",
        "# automática de hiperparâmetros para o modelo LSTM. O Keras-Tuner é uma\n",
        "# biblioteca que permite otimizar automaticamente os hiperparâmetros de um\n",
        "# modelo de aprendizado de máquina.\n",
        "\n",
        "# O build_model é uma função que constrói o modelo LSTM com os hiperparâmetros\n",
        "# ajustáveis. O tuner é criado usando a função RandomSearch, que realiza uma\n",
        "# busca aleatória de hiperparâmetros. É possível definir os hiperparâmetros\n",
        "# a serem ajustados usando as classes do Keras-Tuner, como Int para valores\n",
        "# inteiros e Choice para escolha entre opções.\n",
        "\n",
        "# A busca de hiperparâmetros é realizada chamando o método search do tuner,\n",
        "# passando os dados de treinamento e validação, bem como o número de épocas\n",
        "# para treinamento. Após a busca, você pode obter o melhor modelo encontrado\n",
        "# usando o método get_best_models.\n",
        "\n",
        "# Definir a função de construção do modelo\n",
        "timesteps = window_size\n",
        "input_dim = 1\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
        "                            dropout=hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1),\n",
        "                                input_shape=(timesteps, input_dim)))\n",
        "    model.add(keras.layers.Dense(units=1, activation='linear'))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[0.001, 0.01, 0.1])),\n",
        "                  loss='huber')\n",
        "    return model\n",
        "\n",
        "# Definir os hiperparâmetros a serem ajustados\n",
        "hp = HyperParameters()\n",
        "hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "hp.Choice('learning_rate', values=[0.001, 0.01, 0.1])\n",
        "hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
        "hp.Choice('batch_size', values=[16, 32, 64, 128])  # Adicionando o hiperparâmetro batch_size\n",
        "\n",
        "# Criar o tuner\n",
        "tuner = RandomSearch(build_model, objective='val_loss', max_trials=10, hyperparameters=hp)\n",
        "\n",
        "# Realizar a busca de hiperparâmetros\n",
        "#tuner.search(x=train_data, y=train_labels, epochs=10, validation_data=(val_data, val_labels))\n",
        "tuner.search(x=X_train, y=y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Obter o melhor modelo encontrado\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "best_model.summary()"
      ],
      "metadata": {
        "id": "q25wU6tunJvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "id": "5GkLADcfZUaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKA5UMMrzpfk"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import InputLayer, LSTM, Dense\n",
        "\n",
        "#bath=32\n",
        "#feature=1\n",
        "#timesteps=24\n",
        "#X_train_time_major = np.transpose(X_train, (1, 0, 2))\n",
        "model1 = Sequential()\n",
        "model1.add(InputLayer((window_size, 1)))\n",
        "model1.add(LSTM(192, dropout=0.0))#, dropout=0.1,time_major=True, , time_major=True))\n",
        "# # A camada de dropout=0.3 ajuda a prevenir overfitting\n",
        "model1.add(Dense(8, 'relu'))\n",
        "model1.add(Dense(1, 'linear'))\n",
        "\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLD5Lvv12G3c"
      },
      "outputs": [],
      "source": [
        "cp1= ModelCheckpoint('model1/', save_best_only=True)\n",
        "model1.compile(loss=Huber(), optimizer=Adam(learning_rate=0.01), metrics =[RootMeanSquaredError()])\n",
        "# função de perda huber: model1.compile(loss=MeanSquaredError(), loss=Huber()) é geralmente utilizada em problemas\n",
        "# de regressão, onde se deseja uma função de perda menos sensível a outliers.\n",
        "#model1.compile(loss=\"mse\", optimizer=Adam(learning_rate=0.1), run_eagerly=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osOLDFTKE672"
      },
      "outputs": [],
      "source": [
        "\n",
        "r=model1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[cp1], batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotar a função de perda e RMSE\n",
        "#plt.figure(figsize=(10, 6))\n",
        "plt.plot(r.history[\"loss\"], label=\"Função de perda - LSTM\")\n",
        "plt.plot(r.history[\"val_loss\"], label=\"Val. Função de perda da validação- LSTM\")\n",
        "plt.plot(r.history[\"root_mean_squared_error\"], label=\"RMSE-LSTM\")\n",
        "plt.plot(r.history[\"val_root_mean_squared_error\"], label=\"Val. RMSE-LSTM\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xlabel('Época')"
      ],
      "metadata": {
        "id": "yFHS-At0z_Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_TeIgFNEp21"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model1 = load_model('model1/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d84yGFQNzTs_"
      },
      "outputs": [],
      "source": [
        "train_predictions = model1.predict(X_train).flatten()\n",
        "train_results = pd.DataFrame(data={'Train Predictions': train_predictions, 'Actuals':y_train})\n",
        "#train_results\n",
        "\n",
        "# Recuperar valores nominais originais\n",
        "train_results['Train Predictions'] = scaler.inverse_transform(train_results['Train Predictions'].values.reshape(-1, 1)).flatten()\n",
        "train_results['Actuals'] = scaler.inverse_transform(train_results['Actuals'].values.reshape(-1, 1)).flatten()\n",
        "#train_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqxCon_6Wkq5"
      },
      "outputs": [],
      "source": [
        "#plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_results['Train Predictions'][int(0.8*len(ger_real))-48:int(0.8*len(ger_real))], label=\"Predito pelo treinamento\")\n",
        "plt.plot(train_results['Actuals'][int(0.8*len(ger_real))-48:int(0.8*len(ger_real))], label=\"Valores reais\")\n",
        "#plt.plot(ger_solar_predito_origem[int(0.8*len(ger_real))-48:int(0.8*len(ger_real))], label='Predição original')\n",
        "plt.legend()\n",
        "plt.ylabel('Potência (MW)')\n",
        "plt.xlabel('Instância (# hora)')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation='vertical');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGj0YU3xYGXy"
      },
      "outputs": [],
      "source": [
        "#plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_results['Train Predictions'][:168], label=\"Predito pelo treinamento\")\n",
        "plt.plot(train_results['Actuals'][:168], label=\"Valores reais\")\n",
        "#plt.plot(ger_solar_predito_origem.values[:168], label='Predição original')\n",
        "plt.legend()\n",
        "plt.ylabel('Potência (MW)')\n",
        "plt.xlabel('Instância (# hora)')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation='vertical');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY9qGtXWY1QJ"
      },
      "outputs": [],
      "source": [
        "val_predictions = model1.predict(X_val).flatten()\n",
        "val_results = pd.DataFrame(data={'Val Predictions': val_predictions, 'Actuals':y_val})\n",
        "#val_results\n",
        "\n",
        "# Recuperar valores nominais originais\n",
        "val_results['Val Predictions'] = scaler.inverse_transform(val_results['Val Predictions'].values.reshape(-1, 1)).flatten()\n",
        "val_results['Actuals'] = scaler.inverse_transform(val_results['Actuals'].values.reshape(-1, 1)).flatten()\n",
        "#val_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLNE1nyJZK2H"
      },
      "outputs": [],
      "source": [
        "#plt.plot(val_results['Val Predictions'][:48])\n",
        "#plt.plot(val_results['Actuals'][:48])\n",
        "#plt.figure(figsize=(10, 6))\n",
        "plt.plot(val_results['Val Predictions'][:48], label=\"Predito pela validação\")\n",
        "plt.plot(val_results['Actuals'][:48], label=\"Valores reais\")\n",
        "#plt.plot(ger_solar_predito_origem.values[:48], label='Predição original')\n",
        "plt.legend()\n",
        "plt.ylabel('Potência (MW)')\n",
        "plt.xlabel('Instância (# hora)')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation='vertical');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYfFM9zVZ6OR"
      },
      "outputs": [],
      "source": [
        "test_predictions = model1.predict(X_test).flatten()\n",
        "test_results = pd.DataFrame(data={'Test Predictions': test_predictions, 'Actuals':y_test})\n",
        "#test_results\n",
        "\n",
        "# Recuperar valores nominais originais\n",
        "test_results['Test Predictions'] = scaler.inverse_transform(test_results['Test Predictions'].values.reshape(-1, 1)).flatten()\n",
        "test_results['Actuals'] = scaler.inverse_transform(test_results['Actuals'].values.reshape(-1, 1)).flatten()\n",
        "#test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD5tXB6paQ14"
      },
      "outputs": [],
      "source": [
        "#plt.plot(test_results['Test Predictions'][:48])\n",
        "#plt.plot(test_results['Actuals'][:48])\n",
        "#plt.figure(figsize=(10, 6))\n",
        "plt.plot(test_results['Test Predictions'][-240:], label=\"Predito nos dados de teste\")\n",
        "plt.plot(test_results['Actuals'][-240:], label=\"Valores reais\")\n",
        "#plt.plot(ger_solar_predito_origem.values[48:], label='Predição original')\n",
        "plt.legend()\n",
        "plt.ylabel('Potência (MW)')\n",
        "plt.xlabel('Instância (# hora)')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation='vertical');"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defina a data final dos dados de teste\n",
        "data_final_teste = pd.to_datetime('2018-12-31')\n",
        "\n",
        "# Crie as datas de validação e teste\n",
        "#dates_val = pd.date_range(start='2018-01-01', end=data_final_teste, freq='D')\n",
        "#dates_test = pd.date_range(start=data_final_teste + pd.DateOffset(days=1), end='2019-12-31', freq='D')\n",
        "dates_val = pd.date_range(start='2019-01-01', end=data_final_teste, freq='h')\n",
        "dates_test = pd.date_range(start=data_final_teste + pd.DateOffset(days=1), end='2019-01-31', freq='h')\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "recursive_predictions = []\n",
        "#last_window = deepcopy(X_test[-1])   # Considera o último 1 ponto de dados como preditores\n",
        "last_window = deepcopy(X_test[-720])  # Considera os últimos 720 pontos de dados como preditores\n",
        "recursive_dates = np.concatenate([dates_val, dates_test])\n",
        "\n",
        "for target_date in recursive_dates:\n",
        "    next_prediction = model1.predict(np.array([last_window])).flatten()\n",
        "    recursive_predictions.append(next_prediction[0])\n",
        "    last_window = np.roll(last_window, -1)\n",
        "    last_window[-1] = next_prediction[0]\n",
        "\n",
        "# Crie um DataFrame com as previsões\n",
        "pred_results = pd.DataFrame({'Date': recursive_dates, 'Predictions': recursive_predictions})\n",
        "print(pred_results)"
      ],
      "metadata": {
        "id": "pYQ93Qs_HyFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(10, 6))\n",
        "# Recuperar valores nominais originais\n",
        "pred_results['Predictions'] = scaler.inverse_transform(pred_results['Predictions'].values.reshape(-1, 1)).flatten()\n",
        "\n",
        "plt.plot(pred_results['Date'], pred_results['Predictions'], label='Predição a partir de 02-01-2019')\n",
        "plt.xlabel('Ano-Mês-Dia')\n",
        "plt.xticks(rotation='vertical');\n",
        "plt.ylabel('Demanda de energia (MWh)')\n",
        "#plt.title('Valores previstos ao longo do tempo')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TZKG8jXQ81Tp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}